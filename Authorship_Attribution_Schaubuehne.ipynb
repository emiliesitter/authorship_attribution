{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Authorship Attribution*\n",
    "\n",
    "## *Untersuchung der Texte \"von einem Clown\" in der \"Schaubühne\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import sklearn.decomposition\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy.spatial.distance as scidist\n",
    "import scipy.cluster.hierarchy as hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Einführung und Fragestellung\n",
    "\n",
    "*Die Schaubühne* war eine Wochenzeitschrift, die 1905 vom Berliner Theaterkritiker Siegfried Jacobson gegründet wurde. War sie zuerst eine reine Theater- und Kulturzeitschrift, wurde sie 1918 in *Weltbühne* umbenannt und begann sich auch politischen Themen zu widmen. Die *Schaubühne* erschien wöchentlich und wurde jeweils in zwei Bänden pro Jahr im Umfang von etwa 700 Seiten zusammengefasst. Die Autoren der Artikel sind unterschiedlich, ein großer Teil von ihnen wurde vom Herausgeber Siegfried Jacobson selbst verfasst, daneben finden sich Artikel von prominenten Kritikern wie Julius Bab und Willi Handl, Gedichte, Auszüge aus Dramen und Gastbeiträge von Schauspieler\\*innen, KünstlerInnen, anderen Theaterkritiker\\*innen und Personen aus der Theaterszene der ersten Hälfte des 20. Jahrhunderts (Austrian Academy of Sciences 2022). \n",
    "\n",
    "Einige dieser Artikel wurde aus unterschiedlichen Gründen unter Pseudonymen verfasst, einer davon ist schlichtweg, dass nicht immer wieder dieselben Namen jener Autor\\*innen, die die meisten Artikel schreiben, unter den jeweiligen Texten erscheinen. Die drei Artikel „von einem Clown“ aus den Jahren 1908 bis 1910, deren AutorIn in dieser Arbeit herausgefunden werden soll, befassen sich mit den prekären Arbeitsbedingungen für Schauspieler\\*innen an deutschsprachigen Theatern und der anonyme Autor gibt Insiderinformationen, die ihn gewissermaßen zum Whistleblower machen. In diesem Fall scheint das Pseudonym „Clown“ vor allem zum Schutz des Autors verwendet werden. \n",
    "\n",
    "Die Texte des Clowns bieten sich für die Fallstudie an, da mit drei Artikeln ausreichend Tokens vorliegen und sich die potenziellen Kandidaten durch den Hinweis von Projektleiterin Dr. Imelda Rohrbacher, die an der digitalen Edition der *Schaubühne* arbeitet, dass der „Clown“ Schauspieler war, zumindest etwas einschränken lassen. \n",
    "\n",
    "Grundvoraussetzung für ein Ergebnis der Studie ist, dass der „Clown“ auch unter Klarnamen zumindest einmal in der *Schaubühne* publiziert hat und damit in die Liste der potenziellen Kandidat\\*innen aufgenommen wird. Es ist nicht auszuschließen, dass der „Clown“ nie unter Klarnamen in der Schaubühne publiziert hat und daher nicht berücksichtig werden konnte, da es faktisch unmöglich wäre, zusätzlich ein Referenzkorpus von Schauspieler\\*innen, die in der Zeit um 1910 an deutschen Bühnen aktiv waren, aber *nicht* in der *Schaubühne* publiziert haben, zu erstellen. \n",
    "\n",
    "Von allen SchauspielerInnen, die in der Schaubühne einige Jahre vor und nach Erscheinen der Clown-Texte publiziert haben, konnten sich leider auch nicht genug Referenztexte finden lassen und sie können aufgrund dessen in großen Teilen der Untersuchung nicht berücksichtigt werden. Andererseits ist vielleicht anzunehmen, dass eine Person, die *ausschließlich* Schauspieler\\*in war und sich ansonsten in ihrem gesamten Leben nicht unter Klarnamen schriftstellerisch betätigt hat, auch nicht AutorIn der drei längeren Artikel über einen Zeitraum von drei Jahren hinweg war. \n",
    "\n",
    "Tatsächlich kristallisierten sich unter den Autoren, von denen genug Tokens vorliegen, zwei Kandidaten heraus, die als „Clown“ in Frage kommen. Am Ende erscheint der Schauspieler, Regisseur und Dramaturg Otto Kienscherf als der wahrscheinlichste Autor der „Clown“-Texte. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Datengrundlage\n",
    "\n",
    "Das digitale Editionsprojekt des Austrian Centre for Digital Humanities an der Österreichischen Akademie der Wissenschaften umfasst Annotation der Digitalisate der Schaubühne, Registererstellung, Verknüpfung mit Normdatensätzen, technische Einrichtung und open access-Publikation (ÖAW 2022). Das Projekt läuft seit weniger als zwei Jahren und die Daten sind online noch nicht verfügbar, aufgrund meines Praktikums am ACDH CH verfüge ich aber über frühe Versionen der Digitalisate der Bände 2.1 bis 8.2 (von 1906 bis 1913) im XML-Format. Die Annotationen in diesen Bänden sind noch nicht standardisiert, was aber keine Rolle spielt, da das Markup ohnehin entfernt wird und für diese Untersuchung nur der reine Text behalten wird. \n",
    "\n",
    "Die Korpora wurden hauptsächlich aus Texten dieser Bände der *Schaubühne* zusammengestellt. Wenn dort nur zu wenig Text für einen Autor zu finden ist, wurden die Referenzkorpora, wenn möglich, durch Publikationen der jeweiligen Autoren außerhalb der *Schaubühne* erweitert. Die Referenzkorpora für die beiden Autoren Max Martersteig und Otto Kienscherf, die sich als am wahrscheinlichsten herausgestellt haben, wurden zusätzlich durch mehrere Texte erweitert, um den Vergleich mit einer größeren Textmenge zu ermöglichen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Einlesen der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Einlesen der Clown-Texte\n",
    "\n",
    "Folgende Texte publizierte der anonyme Autor, aufgeteilt auf mehrere Ausgaben, unter dem Pseudonym „Clown“:\n",
    "\n",
    "-\t„Moderne Sklaven“ in Band 3.1\n",
    "-\t„Menschenhandel“ in Band 4.1\n",
    "-\t„Theatertrust“ in Band 4.2\n",
    "\n",
    "Die drei Texte prangern Missstände an Theatern im deutschsprachigen Raum an und befassen sich mit der rechtlichen Situation für dort angestellte Personen. \n",
    "\n",
    "Die Texte werden hier inklusive Markup eingelesen und werden als Values einem Dicitionary angefügt, Keys sind die Namen der Textfiles, in denen die Texte gespeichert wurden (zusammegesetzt aus \"Clown\", Bandnummer, Textitel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_corpus = \"Korpora\"\n",
    "clown_texts = [\"Clown_4_1_Menschenhandel.txt\", \"Clown_4_2_Theatertrust.txt\", \"Clown_3_1_Moderne_Sklaven.txt\"]\n",
    "clown = {}\n",
    "\n",
    "for text in clown_texts:\n",
    "    file_path=os.path.join(path_corpus, text)\n",
    "    with open(file_path, \"r\", encoding=\"utf8\") as f:\n",
    "        clown_text = f.read()\n",
    "        clown[text] = clown_text\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Einlesen der Referenztexte\n",
    "\n",
    "18 Personen qualifizierten sich nach umfangreicher Recherche als Urheber der \"Clown\"-Texte. Die meisten von ihnen sind Schauspieler, da in einer früheren Ausgabe der *Schaubühne* die Clown-Serie mit dem Hinweis, dass die Texte von einem Schauspieler stammen würden, angekündigt wurde. Zusätzlich wurden Richard Treitel und Julius Bab, die Theaterkritiker und keine Schauspieler waren, zu den Referenzkorpora hinzugefügt, da sie viele Artikel, auch unter aufgelösten Pseudonymen, für die *Schaubühne* verfasst haben und sich auch ähnlichen Themen widmen. Die Liste der Schauspieler, die hier als potenzielle Kandidaten genauer untersucht werden, wurde auf Basis der Bände 3.1 bis 8.2 erstellt: grundsätzlich kamen alle Schauspieler, die in diesen Bänden einen Text veröffentlicht haben, in Frage, eingeschränkt wurde diese Anzahl dann noch durch Hinweise von Projektleiterin Dr. Imelda Rohrbacher, die aufgrund ihrer Expertise bestimmte Personen als Autor ausschließen konnte, und durch weitere Recherche zum Hintergrund der potenziellen Kandidaten (Personen, die *ausschließlich* Texte zu gänzlich anderen Themen als allem, was in die juristische oder soziale Richtung geht, publiziert oder sich nur in anderem Genre, wie z.B. Drama, bewegt haben, wurden damit ausgeschlossen) eingeschränkt. \n",
    "\n",
    "Ziel war, in den mir verfügbaren Bänden der *Schaubühne* zumindest Referenztexte im Umfang von 2000 Tokens zu finden. War dies nicht möglich, wurden, wenn möglich, die Referenzkorpora durch externe Quellen erweitert, um zumindest 2000 Tokens zu erreichen. Für Max Martersteig und Otto Kienscherf, die sich als die wahrscheinlichsten Autorenkandidaten herausgestellt haben, wurden noch mehr Referenztexte hinzugefügt. All diese Texte werden hier eingelesen und in einem Dictionary gespeichert, Keys sind jeweils die Namen der Autoren (abgespeichert zuerst in Ordnern, benannt mit Vorname_Nachname der Autoren, die Textfiles benannt mit Nachname, ggf. Band, wenn in der *Schaubühne* publiziert, und bis zu 4 Wörtern des Texttitels). \n",
    "\n",
    "\n",
    "*(__Anmerkung:__ Der relative Pfad funktioniert hier nicht, was mir leider absolut unerklärlich ist und wofür ich keine Lösung finden konnte. Für \"directory\" bitte den absoluten Pfad einsetzen.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"\"\n",
    "authors = [name for name in os.listdir(directory)] # alle Texte sind in nach den Autoren benannten Ordnern gespeichert, ihre Namen werden in einer Liste gespeichert\n",
    "reference = {}\n",
    "\n",
    "for author in authors: \n",
    "    path=os.path.join(directory, author) # Pfad zu den Ordnen für die einzelnen Schauspieler\n",
    "    for filename in os.scandir(path): # iterieren über alle Objekte (als os.DirEntry-Objekte) in den Unterordnern\n",
    "        if not filename.name.endswith('.txt'): # wenn der Name des Files NICHT auf \".txt\" endet ...\n",
    "            continue # ... endet die Iteration und die nächste beginnt\n",
    "        file_path = os.path.join(path, filename) # Pfad zu allen Files in den Unterordnern\n",
    "        if author not in reference.keys(): # wenn es noch keinen Eintrag zum Autor im Reference-Dict gibt, \n",
    "            reference[author] = \"\" # wird hier einer erstellt\n",
    "        with open(file_path, \"r\", encoding=\"utf8\") as f: # die Textdatei wird geöffnet\n",
    "            text = f.read()\n",
    "            reference[author] += text # und ihr Text dem jeweiligen Autor angefügt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Preprocessing\n",
    "\n",
    "### 2.2.1 Allgemeine Vorbereitung der Texte und Referenztexte\n",
    "\n",
    "Im nächsten Schritt werden die Korpora in eine Form gebracht, mit der sie weiterverarbeitet werden können. \n",
    "\n",
    "Zuerst werden die Schreibweisen der Texte vereinheitlicht. Im Frakturdruck werden am Wortbeginn in der Schaubühne und auch einigen anderen Quellen der Referenztexte große J statt I verwendet. Um dies zu vereinheitlichen und auch großgeschreibene und klein geschriebene Wörter vergleichbar zu machen, werden in allen häufigen Wörtern, die eventuell in die Liste der most frequent words aufgenommen werden könnten, diese großen J durch I ersetzt. Auch alle scharfen ß werden durch ss ersetzt, damit hier mögliche verschiedene Schreibweisen kein Problem darstellen. Die Schreibweise *giebt* wird zu *gibt* vereinheitlicht. \n",
    "\n",
    "Als wichtigster Schritt im Preprocessing wird das gesamte Markup der XML-Dateien entfernt. \n",
    "\n",
    "Danach werden die Texte tokenisiert und mit SpaCy lemmatisiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mit häufigen Wörtern, die mit großem J statt I beginnen (können)\n",
    "\n",
    "j_to_i = {\"Jm\": \"im\", \"Jch\": \"ich\", \"Jnnern\": \"innern\", \"Jndien\": \"Indien\", \"Jnszenierung\": \"Inszenierung\", \"Jn\": \"in\", \"Jdeal\": \"Ideal\", \"Jmpression\": \"Impression\", \"Jhr\": \"Ihr\", \"Jdee\": \"Idee\", \"Jllusion\": \"Illusion\", \"Jst\": \"ist\", \"Jhnen\": \"ihnen\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(corpus):\n",
    "    \n",
    "    for text in corpus:\n",
    "        \n",
    "        # Ersetzen der Js durch Is im Fraktur-Digitalisat\n",
    "        for j, i in j_to_i.items():\n",
    "            corpus[text] = re.sub(j, i, corpus[text])\n",
    "            \n",
    "        # Entfernen der Tags und Standardisierung\n",
    "        corpus[text] = re.sub(r'<TITLE>.*</TITLE>', '', corpus[text], count=0) # Entfernen der Texttitel\n",
    "        corpus[text] = re.sub(r'<TITLEPART.*</TITLEPART>', '', corpus[text], count=0) # Entfernen der Texttitel\n",
    "        corpus[text] = re.sub(r'\\n<lb break=\"no\"/>', '', corpus[text]) # Zusammenfügen abgeteilter Wörter\n",
    "        corpus[text] = re.sub(r'<lb/>', ' ', corpus[text]) # Ersetzen der Line-Beginnings durch ein Leerzeichen\n",
    "        corpus[text] = re.sub(r'<fw.*</fw>', '', corpus[text]) # Entfernen der Seitenzahlen\n",
    "        corpus[text] = re.sub(r'ß', 'ss', corpus[text]) # Ersetzen aller scharfen ß\n",
    "        corpus[text] = re.sub(r'giebt', 'gibt', corpus[text]) # Ersetzen von giebt mit gibt für Vereinheitlichung\n",
    "        corpus[text] = re.sub(r'<.*?>', '', corpus[text]) # Entfernen aller übrigen Tags\n",
    "    \n",
    "    # Tokenisieren\n",
    "    corpus_tokenized = {}\n",
    "    for text in corpus: \n",
    "        tokens = word_tokenize(corpus[text])\n",
    "        text_tokenized = [token.lower() for token in tokens if token not in \"./\\_*(),;:!“„?—‘...——.–=§\"]\n",
    "        corpus_tokenized[text] = text_tokenized\n",
    "    \n",
    "    # Lemmatisieren\n",
    "    corpus_lemmatized = {}\n",
    "    for text in corpus_tokenized:\n",
    "        doc = nlp(\" \".join(corpus_tokenized[text]))\n",
    "        text_lemmatized = [token.lemma_ for token in doc]\n",
    "        corpus_lemmatized[text] = text_lemmatized\n",
    "        \n",
    "    return corpus_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_clown = preprocess(clown)\n",
    "reference_corpus = preprocess(reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Es liegen jetzt Referenztexte und die Texte des \"Clowns\" in folgendem Umfang zur weiteren Untersuchung vor:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adolf_Winds: 4635 Tokens\n",
      "Albert_Boree: 2305 Tokens\n",
      "Alfred_Auerbach: 2787 Tokens\n",
      "Alfred_Halm: 1929 Tokens\n",
      "Egon_Friedell: 13379 Tokens\n",
      "Ernst_Clefeld: 2741 Tokens\n",
      "Franz_Blei: 2836 Tokens\n",
      "Franz_Kreidemann: 1804 Tokens\n",
      "Franz_Vallentin: 2258 Tokens\n",
      "Hanns_Hannsen: 4105 Tokens\n",
      "Hans_Olden: 4465 Tokens\n",
      "Julius_Bab: 4427 Tokens\n",
      "Max_Martersteig: 12987 Tokens\n",
      "Max_Pategg: 1589 Tokens\n",
      "Oscar_Sauer: 242 Tokens\n",
      "Otto_Kienscherf: 11118 Tokens\n",
      "Richard_Treitel: 5931 Tokens\n",
      "Rudolf_Bluemner: 2043 Tokens\n"
     ]
    }
   ],
   "source": [
    "for author, text in reference_corpus.items():\n",
    "    print(f\"{author}: {len(text)} Tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clown_4_1_Menschenhandel: 4708\n",
      "Clown_4_2_Theatertrust: 1641\n",
      "Clown_3_1_Moderne_Sklaven: 13683\n"
     ]
    }
   ],
   "source": [
    "for title, text in corpus_clown.items():\n",
    "    text_title = title.split(\".\")[0]\n",
    "    print(f\"{text_title}: {len(text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Splitten des Clown-Corpus in Chunks\n",
    "\n",
    "Für die Untersuchung werden zu Beginn Chunks von je 2000 Tokens verwendet. Die Länge bietet sich an, da für die meisten Autorenkandidaten, wie oben ersichtlich, zumindset ca. 2000 verfügbar sind.\n",
    "\n",
    "Damit der gesamte verfügbare Text des \"Clowns\" verwendet werden kann und nicht nur jeweils die ersten 2000 Tokens, wie das bei den Referenztexten gemacht wird, werden die drei Texte des Clowns in mehrere Chunks von jeweils 2000 Tokens gesplittet. Der zweite, etwas kürzere Text, muss leider in dieser Länge beibehalten werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insgesamt können die Texte des anonymen Autors in 9 Chunks mit einer Länge von maximal 2000 Tokens gesplittet werden.\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 2000\n",
    "\n",
    "clown_chunks = []\n",
    "\n",
    "for text in corpus_clown.values():\n",
    "    \n",
    "    chunk_start = 0\n",
    "    chunk_end = chunk_size\n",
    "    \n",
    "    if len(text) <= chunk_size: # Texte mit einer geringeren Länge als 2000 Tokens werden behalten\n",
    "        clown_chunks.append(text)\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        while chunk_end <= len(text):\n",
    "            clown_chunks.append(text[chunk_start:chunk_end]) #von längeren Texten werden die Tokens 0 bis 1999 genommen\n",
    "            chunk_start += chunk_size # danach werden die Tokens erhöht auf 2000 bis 3999 etc.\n",
    "            chunk_end += chunk_size # solange, bis das Ende des Chunks höher wäre als der Text überhaupt Tokens hat\n",
    "\n",
    "        \n",
    "print(f\"Insgesamt können die Texte des anonymen Autors in {len(clown_chunks)} Chunks mit einer Länge von maximal {chunk_size} Tokens gesplittet werden.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die weitere Verarbeitung müssen die Texte, die momentan noch in Listenform vorliegen, in Strings umgewandelt werden. \n",
    "\n",
    "Für eine besserer Darstellung der Ergebnisse werden diese Strings durchnummeriert. In einer separaten Liste werden ihre Bezeichnungen (\"C\" + eine Nummer) abgespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clown_chunks = [\" \".join(chunk) for chunk in clown_chunks]\n",
    "clown_names = [f\"C{n+1}\" for n in range (len(clown_chunks))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1: 2000\n",
      "C2: 2000\n",
      "C3: 1641\n",
      "C4: 2000\n",
      "C5: 2000\n",
      "C6: 2000\n",
      "C7: 2000\n",
      "C8: 2000\n",
      "C9: 2000\n"
     ]
    }
   ],
   "source": [
    "for name, chunk in zip(clown_names, clown_chunks):\n",
    "    print(f\"{name}: {len(chunk.split(' '))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Kürzen der Referenztexte\n",
    "\n",
    "Von den Referenztexten werden jeweils die ersten 2000 Tokens genommen und als Liste in einem Dictionary abgespeichert, dessen Keys die Namen der Autoren sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adolf_Winds: 2000 Tokens\n",
      "Albert_Boree: 2000 Tokens\n",
      "Alfred_Auerbach: 2000 Tokens\n",
      "Alfred_Halm: 1929 Tokens\n",
      "Egon_Friedell: 2000 Tokens\n",
      "Ernst_Clefeld: 2000 Tokens\n",
      "Franz_Blei: 2000 Tokens\n",
      "Franz_Kreidemann: 1804 Tokens\n",
      "Franz_Vallentin: 2000 Tokens\n",
      "Hanns_Hannsen: 2000 Tokens\n",
      "Hans_Olden: 2000 Tokens\n",
      "Julius_Bab: 2000 Tokens\n",
      "Max_Martersteig: 2000 Tokens\n",
      "Max_Pategg: 1589 Tokens\n",
      "Oscar_Sauer: 242 Tokens\n",
      "Otto_Kienscherf: 2000 Tokens\n",
      "Richard_Treitel: 2000 Tokens\n",
      "Rudolf_Bluemner: 2000 Tokens\n"
     ]
    }
   ],
   "source": [
    "def shorten_corpus(corpus):\n",
    "\n",
    "    corpus_shortened = {}\n",
    "    for k, v in corpus.items():\n",
    "        corpus_shortened[k] = v[:2000]\n",
    "\n",
    "    return(corpus_shortened)\n",
    "\n",
    "reference_shortened = shorten_corpus(reference_corpus)\n",
    "\n",
    "for k, v in reference_shortened.items():\n",
    "    print(f\"{k}: {len(v)} Tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entfernen aller zu kurzen und damit nicht vergleichbaren Texte**\n",
    "\n",
    "Alle Texte mit unter 1800 Tokens werden aussortiert. Auf diese Weise bleibt Franz Kreidemann im Korpus und ist zwar etwas kürzer als 2000 Tokens, Max Pategg und Oscar Sauer können leider nicht weiter überprüft werden und werden erst im nächsten Schritt mit den N-Grammen miteinbezogen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adolf_Winds: 2000 Tokens\n",
      "Albert_Boree: 2000 Tokens\n",
      "Alfred_Auerbach: 2000 Tokens\n",
      "Alfred_Halm: 1929 Tokens\n",
      "Egon_Friedell: 2000 Tokens\n",
      "Ernst_Clefeld: 2000 Tokens\n",
      "Franz_Blei: 2000 Tokens\n",
      "Franz_Kreidemann: 1804 Tokens\n",
      "Franz_Vallentin: 2000 Tokens\n",
      "Hanns_Hannsen: 2000 Tokens\n",
      "Hans_Olden: 2000 Tokens\n",
      "Julius_Bab: 2000 Tokens\n",
      "Max_Martersteig: 2000 Tokens\n",
      "Otto_Kienscherf: 2000 Tokens\n",
      "Richard_Treitel: 2000 Tokens\n",
      "Rudolf_Bluemner: 2000 Tokens\n"
     ]
    }
   ],
   "source": [
    "def remove_less_then_1800_tokens(corpus):\n",
    "\n",
    "    corpus_1800 = {}\n",
    "    \n",
    "    for author, text in corpus.items():\n",
    "        if len(text) >= 1800: # nur wenn ein Text mindestens 1800 Tokens hat ...\n",
    "            corpus_1800[author] = text # ... wird er dem neuen Dictionary hinzugefügt\n",
    "        \n",
    "    return corpus_1800\n",
    "\n",
    "reference_shortened = remove_less_then_1800_tokens(reference_shortened)\n",
    "\n",
    "for k, v in reference_shortened.items():\n",
    "    print(f\"{k}: {len(v)} Tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit die Referenztexte weiterverarbeitet werden können, müssen sie wie die Texte des Clowns in einer Liste von Strings abgespeichert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = [author for author in reference_shortened.keys()]\n",
    "documents = [\" \".join(text) for text in reference_shortened.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Erstellen des Vokabulars\n",
    "\n",
    "Für die Authorship Attribution werden nur die ca. 50 bis 100 häufigsten Funktionswörter des gesuchten Autors mit den Worthäufigkeiten der Autorenkandidaten vergleichen. Diese werden in Listen mit unterschiedlich vielen häufigsten Wörter abgespeichert, sodass diese Listen später als Parameter verwendet werden können und genauer betrachtet werden kann, welche Vokabulargröße in diesem konkreten Fall zu den besten Ergebnissen führt. Es werden dafür die häufigsten Wörter der gesamten drei Clown-Texte gezählt. Bedeutungstragende Wörter, die nur typisch für die drei vom \"Clown\" vorliegenden Texte sind, werden mit *#* gekennzeichnet und später nicht im Vokabular berücksichtigt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auswahl der Most Frequent Words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_mfw = 50\n",
    "#number_of_mfw = 75\n",
    "#number_of_mfw = 100\n",
    "\n",
    "word_count = Counter([word for article in corpus_clown.values() for word in article if word not in \"=.\"]) # Zählen der Wörter ALLER Clown-Texte\n",
    "mfws = [word for word, count in word_count.most_common(number_of_mfw)] # die number_of_mfw-häufigsten Wörter werden einer Liste hinzugefügt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abspeichern der Wörter in einem txt-File:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"mfws_clown.txt\", \"w\") as f: \n",
    "    for word in mfws: \n",
    "        f.write(\"%s\\n\" % word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktion zum Einlesen aller Wörter, die nicht mit *#* gekennzeichnet sind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocab(file):\n",
    "    vocab = [l.strip() for l in open(file) if not l.startswith('#') and l.strip()]\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abspeichern des entsprechenden Vokabulars in einer Liste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 68 83\n",
      "['der', 'ich', 'und', 'sich', 'sein', 'einen', 'zu', 'in', 'mein', 'dies']\n"
     ]
    }
   ],
   "source": [
    "vocab_50 = load_vocab(\"mfws_clown_50.txt\")\n",
    "vocab_75 = load_vocab(\"mfws_clown_75.txt\")\n",
    "vocab_100 = load_vocab(\"mfws_clown_100.txt\")\n",
    "\n",
    "print(len(vocab_50), len(vocab_75), len(vocab_100))\n",
    "print(vocab_50[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Vektorisieren, Normalisieren und Skalieren der Korpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folgende Funktion hat die Referenztexte, die Clown-Texte und das Vokabular in einer bestimmten Größe als Parameter. Im ersten Schritt werden die Texte vektorisiert. Der CountVectorizer erstellt die Document-Term-Matrix für die Referenztexte auf Basis des angegebenen Vokabulars. Output ist ein Array mit der Größe Anzahl Dokumente x Vokabular, in dem die absoluten Häufigkeiten jedes Worts im Vokabular für jedes Dokument gespeichert sind. Danach werden die Werte nach L1-Norm normalisiert. L1 verändert die Werte so, dass die Summe aller Werte für ein Dokument 1 ergibt. Mit dem Scaler im dritten Schritt werden die Z-Scores ermittelt. Z-Scores geben die Entfernung eines Werts vom Mittelpunkt an und berechnen sich durch die Standardabweichung. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_corpus(reference_documents, unknown_documents, vocab_size):\n",
    "    \n",
    "    # Vektorisieren\n",
    "    vectorizer = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\", vocabulary=vocab_size)\n",
    "    v_documents = vectorizer.fit_transform(reference_documents).toarray()\n",
    "    v_unknown = vectorizer.transform(unknown_documents).toarray()\n",
    "    \n",
    "    # Normalisieren nach L1-Norm\n",
    "    p_documents = preprocessing.normalize(v_documents.astype(float), norm='l1')\n",
    "    p_unknown = preprocessing.normalize(v_unknown.astype(float), norm='l1')\n",
    "    \n",
    "    # Berechnen Z-Scores\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    s_reference = scaler.fit_transform(p_documents)\n",
    "    s_clown = scaler.transform(p_unknown)\n",
    "    \n",
    "    return s_reference, s_clown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Untersuchung\n",
    "\n",
    "## 3.1 Methoden\n",
    "\n",
    "Es wurden alle drei im Kurs behandelten Methoden Burrows Delta (mit Tokens und Character-N-Grammen), HAC und PCA angewandt. PCA und HAC stellten sich als schwer zu interpretieren und für diesen konkreten Fall eher unbrauchbar heraus, da auch mit Anpassung der Parameter zu keinen Ergebnissen führen und nicht einmal die Texte des „Clowns“ mit sich selbst clustern. Auch die Delta-Variante, für die Character-N-Gramms anstatt Tokens verwendet werden, ist problematisch. Ziel dieses Ansatzes war, auch jene Autoren, von denen nur wenige Tokens vorliegen, berücksichtigen zu können. Die Ergebnisse sind nicht aussagekräftig und stehen teilweise sogar in Widerspruch zu den Ergebnissen von Delta mit Tokens. Burrows Delta mit Tokens dagegen ermöglicht immerhin eine Eingrenzung der potenziellen Kandidaten und deutet darauf hin, dass Otto Kienscherf hinter dem „Clown“ steckt, auf den die anderen Methoden nicht vermuten lassen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Burrows Delta\n",
    "\n",
    "Burrows Delta ermittelt die Distanz zwischen einem Text (in diesem Fall jedem der Texte des „Clowns“) und einem Referenztext (die Texte der bekannten Autoren). Dafür wird aus den normalisierten Dokumentvektoren, basierend auf den most frequent words, die in der Funktion oben erstellt wurden, im vieldimensionalen Raum mittels euklidischer Distanz, Cosinus oder Cityblock/Manhattan-Distanz oder Abstand gemessen. Der Autor jenes Dokuments mit dem geringsten Abstand wird als wahrscheinlichster Autor für das Dokument unbekannten Autors vorhergesagt (Evert et al. 2017). Dem Ansatz liegt die Theorie zugrunde, dass der Gebrauch von nicht-bedeutungstragenden Funktionswörtern für einen bestimmten Autor über mehrere Texte hinweg konstant ist. Welche der Metriken verwendet wird sowie auch das verwendete Vokabular haben großen Einfluss auf die Ergebnisse. \n",
    "\n",
    "Die Funktion berechnet, falls diese nicht bereits zuvor berechnet wurden, die Z-Scores. Danach werden die Distanzen berechnet und das Dokument mit der geringsten Distanz wird ausgegeben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Delta:\n",
    "    \"\"\"Delta-Based Authorship Attributer.\"\"\"\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit (or train) the attributer.\n",
    "\n",
    "        Arguments:\n",
    "            X: a two-dimensional array of size NxV, where N represents\n",
    "               the number of training documents, and V represents the\n",
    "               number of features used.\n",
    "            y: a list (or NumPy array) consisting of the observed author\n",
    "                for each document in X.\n",
    "\n",
    "        Returns:\n",
    "            Delta: A trained (fitted) instance of Delta.\n",
    "\n",
    "        \"\"\"\n",
    "        self.train_y = np.array(y)\n",
    "        self.scaler = preprocessing.StandardScaler(with_mean=False)\n",
    "        self.train_X = self.scaler.fit_transform(X)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, metric='cityblock'):\n",
    "        \"\"\"Predict the authorship for each document in X.\n",
    "\n",
    "        Arguments:\n",
    "            X: a two-dimensional (sparse) matrix of size NxV, where N\n",
    "               represents the number of test documents, and V represents\n",
    "               the number of features used during the fitting stage of\n",
    "               the attributer.\n",
    "            metric (str, optional): the metric used for computing\n",
    "               distances between documents. Defaults to 'cityblock'.\n",
    "\n",
    "        Returns:\n",
    "            ndarray: the predicted author for each document in X.\n",
    "\n",
    "        \"\"\"\n",
    "        X = self.scaler.transform(X)\n",
    "        dists = scidist.cdist(X, self.train_X, metric=metric)\n",
    "        return self.train_y[np.argmin(dists, axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Burrows Delta mit Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folgende Funktion gibt die **Vorhersage für jeden Clown-Chunk für jede Metrik** aus. \n",
    "\n",
    "Parameter:\n",
    "\n",
    "- Chunks der Referenztexte, die verwendet werden sollen\n",
    "- Clown_Texte, die verwendet werden sollen\n",
    "- Die in Frage kommenden Kandidaten in Form einer Liste\n",
    "- Das entsprechende Vokabular\n",
    "- Die Namen der Clown-Texte, mit denen die Zeilen im Df benannt werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_names = [\"cityblock\", \"cosine\", \"euclidean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_predictions(reference_corpus, unknown_corpus, authors, vocab_size, row_names):\n",
    "    \n",
    "    delta_results = {}\n",
    "    \n",
    "    # Dokumente werden mit dem entsprechenden Vokabular vektorisiert und skaliert\n",
    "    s_reference, s_clown = preprocess_corpus(reference_corpus, unknown_corpus, vocab_size)\n",
    "    \n",
    "    # Delta Classifier wird instantiiert\n",
    "    delta = Delta()  \n",
    "    \n",
    "    # für jede Metrik wird für jeden Chunk des \"Clowns\" eine Vorhersage gemacht\n",
    "    for m in metrics_names:\n",
    "        \n",
    "        delta.fit(s_reference, authors)   # Delta Classifier wird gefitted\n",
    "        preds = delta.predict(s_clown, metric=m) \n",
    "        delta_results[m] = list(preds)\n",
    "        \n",
    "   # die Vorhersagen werden in einem Df abgespeichert\n",
    "    delta_results_df = pd.DataFrame(data=delta_results)\n",
    "    delta_results_df.index = row_names\n",
    "    delta_results_df\n",
    "    \n",
    "    return delta_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vorhersage für alle Chunks von 2000 Tokens für jede Metrik**\n",
    "\n",
    "Zuerst wird die Funktion auf die Chunks von je 2000 Tokens, die oben erstellt wurden, angewandt. (Zu berücksichtigen hier ist hier, dass Chunk 3 vom \"Clown\" etwas kürzer als 2000 Tokens ist!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cityblock</th>\n",
       "      <th>cosine</th>\n",
       "      <th>euclidean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C1</th>\n",
       "      <td>Franz_Kreidemann</td>\n",
       "      <td>Franz_Kreidemann</td>\n",
       "      <td>Franz_Kreidemann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C2</th>\n",
       "      <td>Ernst_Clefeld</td>\n",
       "      <td>Ernst_Clefeld</td>\n",
       "      <td>Ernst_Clefeld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C3</th>\n",
       "      <td>Otto_Kienscherf</td>\n",
       "      <td>Otto_Kienscherf</td>\n",
       "      <td>Otto_Kienscherf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C4</th>\n",
       "      <td>Hanns_Hannsen</td>\n",
       "      <td>Richard_Treitel</td>\n",
       "      <td>Max_Martersteig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C5</th>\n",
       "      <td>Hanns_Hannsen</td>\n",
       "      <td>Richard_Treitel</td>\n",
       "      <td>Hanns_Hannsen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C6</th>\n",
       "      <td>Alfred_Halm</td>\n",
       "      <td>Franz_Vallentin</td>\n",
       "      <td>Alfred_Auerbach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C7</th>\n",
       "      <td>Otto_Kienscherf</td>\n",
       "      <td>Alfred_Halm</td>\n",
       "      <td>Otto_Kienscherf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C8</th>\n",
       "      <td>Hanns_Hannsen</td>\n",
       "      <td>Albert_Boree</td>\n",
       "      <td>Albert_Boree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C9</th>\n",
       "      <td>Hanns_Hannsen</td>\n",
       "      <td>Alfred_Halm</td>\n",
       "      <td>Alfred_Auerbach</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           cityblock            cosine         euclidean\n",
       "C1  Franz_Kreidemann  Franz_Kreidemann  Franz_Kreidemann\n",
       "C2     Ernst_Clefeld     Ernst_Clefeld     Ernst_Clefeld\n",
       "C3   Otto_Kienscherf   Otto_Kienscherf   Otto_Kienscherf\n",
       "C4     Hanns_Hannsen   Richard_Treitel   Max_Martersteig\n",
       "C5     Hanns_Hannsen   Richard_Treitel     Hanns_Hannsen\n",
       "C6       Alfred_Halm   Franz_Vallentin   Alfred_Auerbach\n",
       "C7   Otto_Kienscherf       Alfred_Halm   Otto_Kienscherf\n",
       "C8     Hanns_Hannsen      Albert_Boree      Albert_Boree\n",
       "C9     Hanns_Hannsen       Alfred_Halm   Alfred_Auerbach"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_predictions_df = delta_predictions(documents, clown_chunks, authors, vocab_75, clown_names)\n",
    "delta_predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Frage kamen bisher 16 Autorenkandidaten.\n"
     ]
    }
   ],
   "source": [
    "print(f\"In Frage kamen bisher {len(authors)} Autorenkandidaten.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Anzahl der möglichen Kandidaten wird damit immerhin ziemlich eingeschränkt! Kandidaten, die bei verschiedenem Vokabular nur sehr wenig vorausgesagt werden, können ausgeschieden werden. In Frage scheinen damit noch zu kommen: Kreidemann, Clefeld, Kienscherf, Martersteig, Treitel, Halm, Hannsen\n",
    "\n",
    "Die weiteren Untersuchungen sollen sich auf diese 7 Kandidaten in der engeren Auswahl beschränken, um herauszufinden, ob sich einer oder mehrere von ihnen noch als wahrscheinlicher herausstellen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vergleich der durchschnittlichen Distanz der wahrscheinlichsten Autoren**\n",
    "\n",
    "Diese Funktion berechnet die durchschnittliche Distanz pro Metrik aller 9 Clown-Chunks zu diesen 7 Autoren in der engeren Auswahl. Die folgende Funktion ist in dieser Schreibweise relativ lang, weil der Übersichtlichkeit halber die Abstände für jede Metrik einzeln berechnet werden (ginge alternativ auch in einem Loop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_reduced = (\"Franz_Kreidemann\", \"Otto_Kienscherf\", \"Max_Martersteig\", \"Ernst_Clefeld\", \"Richard_Treitel\", \"Alfred_Halm\", \"Hanns_Hannsen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avg_distances(vocab_size):\n",
    "\n",
    "    # Dokumente werden mit dem entsprechenden Vokabular vektorisiert und skaliert\n",
    "    s_reference, s_clown = preprocess_corpus(documents, clown_chunks, vocab_size)\n",
    "\n",
    "    # Distanzen mit Cityblock werden berechnet und einem Dict angefügt\n",
    "    sum_distances = {}\n",
    "    for c, doc_name in zip(s_clown, clown_names):\n",
    "        distances = [ scidist.cityblock(c, doc) for doc in s_reference]\n",
    "\n",
    "        for distance, author in zip(distances, authors):\n",
    "            if author in authors_reduced:\n",
    "                if author not in sum_distances.keys(): \n",
    "                    sum_distances[author] = distance\n",
    "                else: \n",
    "                    sum_distances[author] += distance\n",
    "                                    \n",
    "    avg_distances_cb = {}\n",
    "\n",
    "    for author, distance in sum_distances.items():\n",
    "        avg_distance = distance/len(clown_names)\n",
    "        avg_distances_cb[author] = avg_distance\n",
    "\n",
    "    \n",
    "    # Distanzen mit Cosinus werden berechnet und einem Dict angefügt\n",
    "    sum_distances = {}\n",
    "\n",
    "    for c, doc_name in zip(s_clown, clown_names):\n",
    "        distances = [ scidist.cosine(c, doc) for doc in s_reference]\n",
    "\n",
    "        for distance, author in zip(distances, authors):\n",
    "            if author in authors_reduced:\n",
    "                if author not in sum_distances.keys(): \n",
    "                    sum_distances[author] = distance\n",
    "                else: \n",
    "                    sum_distances[author] += distance\n",
    "\n",
    "    avg_distances_cs = {}\n",
    "\n",
    "    for author, distance in sum_distances.items():\n",
    "        avg_distance = distance/len(clown_names)\n",
    "        avg_distances_cs[author] = avg_distance\n",
    "                    \n",
    "    \n",
    "    # Euklidische Distanzen werden berechnet und einem Dict angefügt\n",
    "    sum_distances = {}\n",
    "\n",
    "    for c, doc_name in zip(s_clown, clown_names):\n",
    "        distances = [ scidist.euclidean(c, doc) for doc in s_reference]\n",
    "\n",
    "        for distance, author in zip(distances, authors):\n",
    "            if author in authors_reduced:\n",
    "                if author not in sum_distances.keys(): \n",
    "                    sum_distances[author] = distance\n",
    "                else: \n",
    "                    sum_distances[author] += distance\n",
    "\n",
    "    avg_distances_ed = {}\n",
    "\n",
    "    for author, distance in sum_distances.items():\n",
    "        avg_distance = distance/len(clown_names)\n",
    "        avg_distances_ed[author] = avg_distance\n",
    "        \n",
    "        \n",
    "    # Die durchschnittliche Distanz für jede Metrik wird berechnet\n",
    "    avg_distances = {}\n",
    "\n",
    "    for author in avg_distances_cb.keys():\n",
    "        avg_distances[author] = []\n",
    "        avg_distances[author].append(avg_distances_cb[author])\n",
    "        avg_distances[author].append(avg_distances_cs[author])\n",
    "        avg_distances[author].append(avg_distances_ed[author])\n",
    "    \n",
    "        \n",
    "    # Ausgabe in Form eines DF\n",
    "    distances_df = pd.DataFrame(data=avg_distances)\n",
    "    distances_df.index = metrics_names\n",
    "    return distances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alfred_Halm</th>\n",
       "      <th>Ernst_Clefeld</th>\n",
       "      <th>Franz_Kreidemann</th>\n",
       "      <th>Hanns_Hannsen</th>\n",
       "      <th>Max_Martersteig</th>\n",
       "      <th>Otto_Kienscherf</th>\n",
       "      <th>Richard_Treitel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cityblock</th>\n",
       "      <td>55.285150</td>\n",
       "      <td>61.163589</td>\n",
       "      <td>58.854552</td>\n",
       "      <td>58.187146</td>\n",
       "      <td>61.206541</td>\n",
       "      <td>52.659890</td>\n",
       "      <td>58.146782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cosine</th>\n",
       "      <td>0.857761</td>\n",
       "      <td>0.942606</td>\n",
       "      <td>0.957902</td>\n",
       "      <td>0.910097</td>\n",
       "      <td>1.084253</td>\n",
       "      <td>0.952765</td>\n",
       "      <td>1.003292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>euclidean</th>\n",
       "      <td>10.788628</td>\n",
       "      <td>11.561428</td>\n",
       "      <td>11.147931</td>\n",
       "      <td>11.134282</td>\n",
       "      <td>11.508061</td>\n",
       "      <td>10.218258</td>\n",
       "      <td>11.219693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Alfred_Halm  Ernst_Clefeld  Franz_Kreidemann  Hanns_Hannsen  \\\n",
       "cityblock    55.285150      61.163589         58.854552      58.187146   \n",
       "cosine        0.857761       0.942606          0.957902       0.910097   \n",
       "euclidean    10.788628      11.561428         11.147931      11.134282   \n",
       "\n",
       "           Max_Martersteig  Otto_Kienscherf  Richard_Treitel  \n",
       "cityblock        61.206541        52.659890        58.146782  \n",
       "cosine            1.084253         0.952765         1.003292  \n",
       "euclidean        11.508061        10.218258        11.219693  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_avg_distances(vocab_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alfred_Halm</th>\n",
       "      <th>Ernst_Clefeld</th>\n",
       "      <th>Franz_Kreidemann</th>\n",
       "      <th>Hanns_Hannsen</th>\n",
       "      <th>Max_Martersteig</th>\n",
       "      <th>Otto_Kienscherf</th>\n",
       "      <th>Richard_Treitel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cityblock</th>\n",
       "      <td>99.463236</td>\n",
       "      <td>110.402730</td>\n",
       "      <td>98.565690</td>\n",
       "      <td>103.020016</td>\n",
       "      <td>103.796473</td>\n",
       "      <td>93.953258</td>\n",
       "      <td>104.201026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cosine</th>\n",
       "      <td>0.896989</td>\n",
       "      <td>0.990478</td>\n",
       "      <td>0.980553</td>\n",
       "      <td>0.961032</td>\n",
       "      <td>1.054432</td>\n",
       "      <td>0.943190</td>\n",
       "      <td>0.992762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>euclidean</th>\n",
       "      <td>14.483628</td>\n",
       "      <td>15.799202</td>\n",
       "      <td>14.296343</td>\n",
       "      <td>15.070170</td>\n",
       "      <td>14.680472</td>\n",
       "      <td>13.801650</td>\n",
       "      <td>15.153937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Alfred_Halm  Ernst_Clefeld  Franz_Kreidemann  Hanns_Hannsen  \\\n",
       "cityblock    99.463236     110.402730         98.565690     103.020016   \n",
       "cosine        0.896989       0.990478          0.980553       0.961032   \n",
       "euclidean    14.483628      15.799202         14.296343      15.070170   \n",
       "\n",
       "           Max_Martersteig  Otto_Kienscherf  Richard_Treitel  \n",
       "cityblock       103.796473        93.953258       104.201026  \n",
       "cosine            1.054432         0.943190         0.992762  \n",
       "euclidean        14.680472        13.801650        15.153937  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_avg_distances(vocab_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anmerkung:** Ein kleineres Vokabular führt zu insgesamt niedrigeren Distanzen, aber damit nicht automatisch besseren Ergebnissen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ergebnisse der durchschnittlichen Distanzen für die 7 wahrscheinlichsten Autoren**:\n",
    "\n",
    "Die Vokabulargröße scheint auf die durchschnittlichen Distanzen aller Chunks keinen besonders großen Einfluss zu haben. Cityblock tendiert immer zu Martersteig und Kienscherf, Kosinus zu Halm und Kienscherf, euklidische Distanz zu Martersteig und Kienscherf. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vorhersage für die drei wahrscheinlichsten Kandidaten**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Von den sieben übrigen Kandidaten schaffen es damit drei in die noch engere Auswahl. Im Folgenden werden nur Texte dieser 3 Autoren mit dem Clown verglichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = [\"Otto_Kienscherf\", \"Max_Martersteig\", \"Alfred_Halm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_reduced = {}\n",
    "for candidate in candidates: \n",
    "    reference_reduced[candidate] = reference_shortened[candidate]\n",
    "\n",
    "documents_reduced = [\" \".join(text) for text in reference_reduced.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cityblock</th>\n",
       "      <th>cosine</th>\n",
       "      <th>euclidean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C1</th>\n",
       "      <td>Alfred_Halm</td>\n",
       "      <td>Max_Martersteig</td>\n",
       "      <td>Max_Martersteig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C2</th>\n",
       "      <td>Max_Martersteig</td>\n",
       "      <td>Max_Martersteig</td>\n",
       "      <td>Max_Martersteig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C3</th>\n",
       "      <td>Otto_Kienscherf</td>\n",
       "      <td>Otto_Kienscherf</td>\n",
       "      <td>Otto_Kienscherf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C4</th>\n",
       "      <td>Max_Martersteig</td>\n",
       "      <td>Max_Martersteig</td>\n",
       "      <td>Max_Martersteig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C5</th>\n",
       "      <td>Alfred_Halm</td>\n",
       "      <td>Otto_Kienscherf</td>\n",
       "      <td>Otto_Kienscherf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C6</th>\n",
       "      <td>Alfred_Halm</td>\n",
       "      <td>Otto_Kienscherf</td>\n",
       "      <td>Otto_Kienscherf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C7</th>\n",
       "      <td>Otto_Kienscherf</td>\n",
       "      <td>Otto_Kienscherf</td>\n",
       "      <td>Otto_Kienscherf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C8</th>\n",
       "      <td>Otto_Kienscherf</td>\n",
       "      <td>Otto_Kienscherf</td>\n",
       "      <td>Otto_Kienscherf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C9</th>\n",
       "      <td>Otto_Kienscherf</td>\n",
       "      <td>Otto_Kienscherf</td>\n",
       "      <td>Otto_Kienscherf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cityblock           cosine        euclidean\n",
       "C1      Alfred_Halm  Max_Martersteig  Max_Martersteig\n",
       "C2  Max_Martersteig  Max_Martersteig  Max_Martersteig\n",
       "C3  Otto_Kienscherf  Otto_Kienscherf  Otto_Kienscherf\n",
       "C4  Max_Martersteig  Max_Martersteig  Max_Martersteig\n",
       "C5      Alfred_Halm  Otto_Kienscherf  Otto_Kienscherf\n",
       "C6      Alfred_Halm  Otto_Kienscherf  Otto_Kienscherf\n",
       "C7  Otto_Kienscherf  Otto_Kienscherf  Otto_Kienscherf\n",
       "C8  Otto_Kienscherf  Otto_Kienscherf  Otto_Kienscherf\n",
       "C9  Otto_Kienscherf  Otto_Kienscherf  Otto_Kienscherf"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_predictions(documents_reduced, clown_chunks, candidates, vocab_75, clown_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Halm wird nur sehr wenig vorhergesagt und ist damit wohl auch eher auszuschließen. Es bleiben **Martersteig** und **Kienscherf** Kandidaten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vorhersagen für die zwei wahrscheinlichsten Kandidaten mit größeren Text-Chunks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Von den jetzt übrigen Kandidaten sollen größere Chunks zur Überprüfung verwendet werden, um zu sehen, ob sich hier noch jemand als wahrscheinlicher als der andere herausstellt. \n",
    "\n",
    "Welche Autoren jetzt genau berücksichtigt werden und wie groß die Chunks sind, kann angepasst werden. Eine Größe von 3700 Tokens ermöglicht immerhin die Bildung von drei Chunks pro Kandidat. Nimmt man einen zusätzlichen Autor, der sich bereits zuvor als sehr unwahrscheinlich herausgestellt hat, in die Liste der Kandidaten auf (es wurde Egon Friedell verwendet, da von ihm ausreichend Tokens vorhanden sind), kann so auch überprüft werden, welche Vokabulargröße vielleicht dazu tendiert, etwas Falsches vorherzusagen, oder für welchen Clown-Chunk die Vorhersage nur schlecht funktioniert. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitten der eingegrenzten Texte und des Clown-Corpus in Chunks**\n",
    "\n",
    "Von den Referenztexten der zwei übrig gebliebenen Kandidaten werden jeweils *chunk_size* Tokens genommen, wobei sich *chunk_size* 4600 als am verlässlichsten erweist.\n",
    "\n",
    "Im Unterschied zu den Chunks mit einer Länge von 2000, die vorher vom Clown zuvor gebildet wurden (weshalb auch nicht die Funktion von oben verwendet wird), werden an dieser Stelle nicht jeweils die ersten *chunk_size* Tokens von jedem der 3 Clown-Texte verwendet, sondern auch von allen Texten des Clowns werden alle Tokens werden in eine Liste gegeben, aus welcher Chunks in der Größe *chunk_size* gebildet werden (ggf. mit Text-Überschneidungen), um auf diese Weise mehr Chunks zu erhalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Otto_Kienscherf_1: 4600 Tokens\n",
      "Otto_Kienscherf_2: 4600 Tokens\n",
      "Max_Martersteig_1: 4600 Tokens\n",
      "Max_Martersteig_2: 4600 Tokens\n",
      "Egon_Friedell_1: 4600 Tokens\n",
      "Egon_Friedell_2: 4600 Tokens\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 4600\n",
    "number_of_chunks = 2\n",
    "\n",
    "#candidates = [\"Otto_Kienscherf\", \"Max_Martersteig\"]\n",
    "candidates = [\"Otto_Kienscherf\", \"Max_Martersteig\", \"Egon_Friedell\"]\n",
    "\n",
    "candidates_chunks = []\n",
    "chunk_names = []\n",
    "\n",
    "for candidate in candidates: \n",
    "    \n",
    "    chunk_start = 0\n",
    "    chunk_end = chunk_size\n",
    "    \n",
    "    while chunk_end <= chunk_size * number_of_chunks:\n",
    "        text = reference_corpus[candidate][chunk_start:chunk_end]\n",
    "        candidates_chunks.append(text)\n",
    "        chunk_names.append(f\"{candidate}_{int(chunk_end/chunk_size)}\")\n",
    "        chunk_start += chunk_size\n",
    "        chunk_end += chunk_size\n",
    "    \n",
    "for candidate, tokens in zip(chunk_names, candidates_chunks):\n",
    "    print(f\"{candidate}: {len(tokens)} Tokens\")\n",
    "    \n",
    "candidates_chunks = [\" \".join(chunk) for chunk in candidates_chunks]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insgesamt können die Texte des anonymen Autors in 4 Chunks mit einer Länge von 4600 Tokens gesplittet werden.\n",
      "['C_big_1', 'C_big_2', 'C_big_3', 'C_big_4']\n"
     ]
    }
   ],
   "source": [
    "# Alle Tokens des Clowns werden in eine Liste gegeben, wo sie weiter gesplittet werden\n",
    "clown_all_texts = [word for text in corpus_clown.values() for word in text]\n",
    "\n",
    "clown_big_chunks = []\n",
    "big_chunks_names = []\n",
    "\n",
    "chunk_start = 0\n",
    "chunk_end = chunk_size\n",
    "\n",
    "while chunk_end <= len(clown_all_texts):\n",
    "    if len(clown_all_texts[chunk_start:chunk_end]) == chunk_size: # solange ein Chunk nicht kürzer als 3700 wird:\n",
    "        clown_big_chunks.append(clown_all_texts[chunk_start:chunk_end]) # werden die Tokens 0 bis 3699 genommen\n",
    "        big_chunks_names.append(f\"C_big_{int(chunk_end/chunk_size)}\")\n",
    "        chunk_start += chunk_size # danach werden die Tokens erhöht auf 3700 bis 7399 etc.\n",
    "        chunk_end += chunk_size\n",
    "\n",
    "clown_big_chunks = [\" \".join(chunk) for chunk in clown_big_chunks]        \n",
    "print(f\"Insgesamt können die Texte des anonymen Autors in {len(clown_big_chunks)} Chunks mit einer Länge von {chunk_size} Tokens gesplittet werden.\")\n",
    "print(big_chunks_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vorhersage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cityblock</th>\n",
       "      <th>cosine</th>\n",
       "      <th>euclidean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C_big_1</th>\n",
       "      <td>Otto_Kienscherf_2</td>\n",
       "      <td>Otto_Kienscherf_2</td>\n",
       "      <td>Otto_Kienscherf_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_big_2</th>\n",
       "      <td>Otto_Kienscherf_1</td>\n",
       "      <td>Otto_Kienscherf_1</td>\n",
       "      <td>Otto_Kienscherf_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_big_3</th>\n",
       "      <td>Otto_Kienscherf_1</td>\n",
       "      <td>Otto_Kienscherf_1</td>\n",
       "      <td>Otto_Kienscherf_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_big_4</th>\n",
       "      <td>Otto_Kienscherf_1</td>\n",
       "      <td>Otto_Kienscherf_1</td>\n",
       "      <td>Otto_Kienscherf_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 cityblock             cosine          euclidean\n",
       "C_big_1  Otto_Kienscherf_2  Otto_Kienscherf_2  Otto_Kienscherf_2\n",
       "C_big_2  Otto_Kienscherf_1  Otto_Kienscherf_1  Otto_Kienscherf_1\n",
       "C_big_3  Otto_Kienscherf_1  Otto_Kienscherf_1  Otto_Kienscherf_1\n",
       "C_big_4  Otto_Kienscherf_1  Otto_Kienscherf_1  Otto_Kienscherf_1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_predictions_reduced = delta_predictions(candidates_chunks, clown_big_chunks, chunk_names, vocab_75, big_chunks_names)\n",
    "delta_predictions_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ergebnisse der Vorhersage für die zwei wahrscheinlichsten Kandidaten**\n",
    "\n",
    "Für den ersten Chunk bei einer Chunk-Größe von 5000 bzw. bei den ersten beiden Chunks des Clowns bei kleinerer Chunk-Größe  wird, wenn Friedell in die Liste der Kandidaten aufgenommen wird, oft Friedell vorhergesagt. Dieser erste Chunk ist daher anscheinend nicht unbedingt repräsentativ für den Clown und wird bei der Auswertung weniger berücksichtigt. \n",
    "\n",
    "**3 Chunks pro Kandidat mit je 3700 Tokens:**\n",
    "\n",
    "Überhaupt keine eindeutigen Ergebnisse, abhängig von der Vokabulargröße verändern sich die Vorhersagen, für dieselben Chunks wird von den verschiedenen Metriken oft etwas anders vorhergesagt. (Für die Chunks C_big_3 bis C_big_5 sind immerhin Kienscherf und Martersteig konsistent und der sehr unwahrscheinliche Friedell wird nicht vorhergesagt.)\n",
    "\n",
    "**2 Chunks pro Kandidat mit je 5550 Tokens:**\n",
    "\n",
    "Nimmt man Friedell zur Überprüfung in die Liste der Kandidaten auf, wird dieser fast immer für den ersten Chunk vorhergesagt. Je höher hier die Vokabulargröße ist, desto eindeutiger wird Kienscherf vorhergesagt. Nimmt man Friedell aus der Liste der Kandidaten, wird für den ersten Chunk Martersteig vorhergesagt. Angesichts der Tatsache, dass ansonsten Friedell vorhergesagt wird, erscheint dies auf jeden Fall weniger verlässlich als die Vorhersage von Kienscherf in den anderen Chunks, die konsistent ist. \n",
    "\n",
    "**2 Chunks pro Kandidat mit 4600 Tokens:**\n",
    "\n",
    "Als \"Kompromiss\", falls 3700 zu kleine Chunks oder 5500 zu große Chunks ergibt. Die Vorhersage bei dieser Größe erweist sich tatsächlich am konstantesten und geht eindeutig in Richtung Kienscherf, der zumindest Delta zufolge der Clown zu sein scheint. Andererseits sind die potenziellen Kandidaten bereits sehr reduziert und es ist nicht auszuschließen, dass der richtige z.B. bereits aussortiert wurde, weil zu wenig Tokens vorliegen, oder von Beginn an nicht als Kandidat in Erwägung gezogen wurde. Friedell wird hier, wenn er zur Überprüfung in die Liste aufgenommen wird, außer bei einer Vokabulargröße von 100 für den ersten Chunk auch nicht vorausgesagt.\n",
    "\n",
    "Auffällig hier ist, dass hauptsächlich die größte Ähnlichkeit zum ersten Textchunk von Kienscherf vorhergesagt wird. Man muss an dieser Stelle jedoch berücksichtigen, dass sich in der *Schaubühne* aus dem Zeitraum, in dem auch der \"Clown\" geschrieben hat, nur ein einziger Text von Kienscherf finden ließ, der ca. 2000 Tokens umfasst und Teil dieses ersten Chunks ist. Ebenfalls Teil des ersten Chunks sind die Tokens eines extern von der Schaubühne publizierten Texts aus dem Jahr 1902. Der zweite Textchunk setzt sich aus späteren externen Texten, um das Jahr 1930 herum und damit 20 Jahre nach den \"Clown\"-Texten, zusammen (da dies die einzigen Referenztexte waren, die sich von Kienscherf finden ließen). Möglicherweise kann man hier einfach Veränderungen in Kienscherfs Stil über diese zwei Jahrzehnte hinweg beobachten, sodass die geringere Nähe zu den früheren Texten ermittelt wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Burrows Delta mit N-Grammen\n",
    "\n",
    "Damit die Texte aller Autorenkandidaten in die Untersuchung miteinbezogen werden können, werden im Folgenden statt Tokens N-Gramme aus Zeichen verwendet. Es werden für jeden Text genau so viele N-Gramme verwendet, wie sich aus dem kürzesten der Referenztexte bilden lassen. Das Markup wird entfernt, die Wörter in den Texten werden aber nicht lemmatisiert. J/I und ß/ss werden dennoch vereinheitlicht, weil diese Entscheidungen wohl genauso beim Herausgeber liegen können wie beim Autor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Funktion zum Erzeugen der N-Gramme**\n",
    "\n",
    "Folgende Funktion enthält zuerst das Preprocessing, dem auch die Tokens unterlaufen sind (mit dem Unterschied, dass jetzt auch die Leerzeichen entfernt werden); danach wird die Anzahl an N-Grammen, die maximal erzeugt werden können, damit für alle Texte gleich viele N-Gramme vorhanden sind, ermittelt; im letzten Schritt werden schließlich dieser Anzahl entsprechend viele N-Gramme erzeugt. Der Parameter *n* gibt an, wie viele Zeichen die N-Gramme enthalten sollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ngrams(corpus, n):\n",
    "\n",
    "    texts = corpus.copy()\n",
    "    characters = {}\n",
    "    ngrams = {}\n",
    "\n",
    "    for text in texts:\n",
    "\n",
    "        # Ersetzen der Js durch Is im Fraktur-Digitalisat\n",
    "        for j, i in j_to_i.items():\n",
    "            texts[text] = re.sub(j, i, texts[text])\n",
    "\n",
    "        # Entfernen der Tags und Standardisierung\n",
    "        texts[text] = re.sub(r'<TITLE>.*</TITLE>', '', texts[text], count=0) # Entfernen der Titel\n",
    "        texts[text] = re.sub(r'<TITLEPART.*</TITLEPART>', '', texts[text], count=0)\n",
    "        texts[text] = re.sub(r'\\n<lb break=\"no\"/>', '', texts[text]) # Zusammenfügen abgeteilter Wörter\n",
    "        texts[text] = re.sub(r'<lb/>', '', texts[text]) # Entfernen der Line-Beginnings\n",
    "        texts[text] = re.sub(r'<fw.*</fw>', '', texts[text]) # Entfernen der Seitenzahlen\n",
    "        texts[text] = re.sub(r'ß', 'ss', texts[text]) # Entfernen aller scharfen ß\n",
    "        texts[text] = re.sub(r'<.*?>', '', texts[text]) # Entfernen aller übrigen Tags\n",
    "        texts[text] = re.sub(r'\\n', '', texts[text]) # Entfernen der neuen Zeilen\n",
    "        texts[text] = re.sub(r' ', '', texts[text]) # Entfernen der Leerzeichen\n",
    "        corpus[text] = re.sub(r'giebt', 'gibt', corpus[text]) # Ersetzen von giebt mit gibt für Vereinheitlichung\n",
    "\n",
    "        #Einfügen der einzelnen Buchstaben der Texte in eine Liste\n",
    "        texts[text] = [char.lower() for token in texts[text] for char in token if char not in \"./\\_*(),;:!“„?—‘...——.–=§\"]\n",
    "        characters[text] = texts[text]\n",
    "\n",
    "    # Den kürzesten Text herausfinden und damit, wie viele N-Grams pro Text erzeugt werden sollen\n",
    "    max_chars = 0 # die Variable wird zuerst auf 0 gesetzt\n",
    "    for text in characters.values():\n",
    "        if max_chars == 0: # wenn über den ersten Text iteriert wird, wird max_chars auf dessen Zeichenlänge gesetzt\n",
    "            max_chars = len(text)        \n",
    "        else:\n",
    "            if max_chars > len(text): # wenn später über einen kürzeren Text iteriert wird ...\n",
    "                max_chars = len(text) # wird max_chars entsprechend angepasst\n",
    "\n",
    "    # Erzeugen der N-Gramme\n",
    "    for author, text in characters.items():\n",
    "\n",
    "        beginning = 0\n",
    "        end = n\n",
    "        ngram_list = []\n",
    "\n",
    "        while end <= max_chars: # Es wird iteriert, solange das Ende eines N-Gramms noch vor Textende ist\n",
    "            ngram = \"\".join(text[beginning:end]) # Die Elemente der Liste werden zu N-Grammen zusammengefügt\n",
    "            ngram_list.append(\"\".join(text[beginning:end])) # Die N-Gramme werden in einer Liste gespeichert\n",
    "            beginning += n # das nächste N-Gramm beginnt z.B. 3 Zeichen später\n",
    "            end += n\n",
    "\n",
    "        ngrams[author] = ngram_list # dem Dictionary mit N-Grammen wird der Name des Autors sowie die N-Gramm-Liste angehängt\n",
    "        \n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Erstellen von 3- und 4-Grammen für Clown und Kandidaten**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_grams_reference = create_ngrams(reference, 3)\n",
    "three_grams_clown = create_ngrams(clown, 3)\n",
    "\n",
    "four_grams_reference = create_ngrams(reference, 4)\n",
    "four_grams_clown = create_ngrams(clown, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wen', 'nvo', 'nir', 'gen', 'dei', 'ner', 'sta', 'dtb', 'eha', 'upt']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_grams_reference[\"Adolf_Winds\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vorhersage mit den N-Grammen**\n",
    "\n",
    "Die Funktion umfasst dieselben Schritte, die auch die Tokens für die Vorhersage mit Delta unterlaufen (zuerst Umwandlung der Dictionaries in Listen, vektorisieren, normalisieren und skalieren, Anwendung von Delta) und wird daher nicht gesondert beschrieben. Neben den jeweigen Dicitionaries mit den N-Grammen nimmt die Funktion auch die Parameter max_features (wie viele N-Gramme der Vektorizer berücksichtigen soll) und metric (cityblock, euclidean, cosine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ngrams(ngrams_reference, ngrams_clown, max_features, metric):\n",
    "    \n",
    "    # Umwandlung der Dicitionaries in Listen\n",
    "    authors_ngrams = [author for author in ngrams_reference.keys()]\n",
    "    reference_ngrams = [\" \".join(text) for text in ngrams_reference.values()]\n",
    "    clown_texts = [author for author in ngrams_clown.keys()]\n",
    "    ngrams_clown = [\" \".join(text) for text in ngrams_clown.values()]\n",
    "    \n",
    "    # Vektorisieren und Normalisieren\n",
    "    vectorizer = CountVectorizer(max_features=max_features)                               \n",
    "    v_ngrams = vectorizer.fit_transform(reference_ngrams).toarray()\n",
    "    ngrams_preprocessed = preprocessing.normalize(v_ngrams.astype(float), norm='l1')\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    s_ngrams = scaler.fit_transform(ngrams_preprocessed)\n",
    "\n",
    "    # Skalisieren\n",
    "    v_ngrams_clown = vectorizer.transform(ngrams_clown).toarray()\n",
    "    ngrams_clown_preprocessed = preprocessing.normalize(v_ngrams_clown.astype(float), norm='l1')\n",
    "    s_ngrams_clown = scaler.transform(ngrams_clown_preprocessed)\n",
    "    \n",
    "    # Vorhersage mit Delta\n",
    "    delta = Delta()                            \n",
    "    delta.fit(s_ngrams, authors_ngrams)\n",
    "    preds = delta.predict(s_ngrams_clown, metric=metric)\n",
    "    \n",
    "    for clown_text, pred in zip(clown_texts, preds):\n",
    "        print(f'{clown_text} mit {metric} und {max_features} Features: {pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clown_4_1_Menschenhandel.txt mit cityblock und 75 Features: Richard_Treitel\n",
      "Clown_4_2_Theatertrust.txt mit cityblock und 75 Features: Max_Pategg\n",
      "Clown_3_1_Moderne_Sklaven.txt mit cityblock und 75 Features: Richard_Treitel\n"
     ]
    }
   ],
   "source": [
    "predict_ngrams(three_grams_reference, three_grams_clown, 75, \"cityblock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clown_4_1_Menschenhandel.txt mit cosine und 50 Features: Ernst_Clefeld\n",
      "Clown_4_2_Theatertrust.txt mit cosine und 50 Features: Max_Pategg\n",
      "Clown_3_1_Moderne_Sklaven.txt mit cosine und 50 Features: Hanns_Hannsen\n"
     ]
    }
   ],
   "source": [
    "predict_ngrams(four_grams_reference, four_grams_clown, 50, \"cosine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cityblock hat eine Tendenz zu Richard Treitel. Die oben als sich wahrscheinlich herausgestellten Kandidaten Kienscherf und Martersteig werden mit kaum einer Kombination an Parametern durch N-Gramme vorhergesagt. Die Ergebnisse scheinen nicht besonders verlässlich und Delta mit N-Grammen daher als keine geeignete Methode für die vorliegenden Korpora. In dem unwahrscheinlichen Fall, dass Oscar Sauer, für den gerade einmal 242 Tokens vorliegen, der \"Clown\" ist, gibt es also leider keine Möglichkeit, dies zu beweisen. Wie erwähnt ist aber eher nicht davon auszugehen, dass jemand, der, zumindest soweit sich das ca. 110 Jahre später, nach umfangreicher Recherche, feststellen lässt, in seinem ganzen Leben keinen Text öffentlich unter Klarnamen publiziert hat, unter Pseudonym drei Serien von Arikeln für die *Schaubühne* geschreiben hat. Die beiden kurzen Beiträge von Oscar Sauer, die sich in der *Schaubühne* finden lassen und zusammen die 242 Tokens ausmachen, sind kurze Statements zu den Themen \"Schauspieleraustausch\" und \"Schauspielerübernahme\", zu denen mehrere Schauspieler\\*innen ihre Meinung in einem kurzen Absatz mitteilten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 PCA und HAC\n",
    "\n",
    "Als weiterer Ansatz, um den Autor hinter den \"Clown\"-Texten zu identifizieren, können Principal Component Analysis (PCA) und Hierarchical Agglomerative Clustering (HAC) verwendet werden.\n",
    "\n",
    "\n",
    "### 3.3.1 Vorbereiten der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für PCA und HAC sollen wieder Chunks von je ca. 2000 Tokens verwendet werden. Sind von einem Autor mehr Tokens verfügbar, können mit dem Parameter max_amount_of_chunks auch mehr Chunks verwendet werden. Sind nicht genug Tokens dafür vorhanden, werden kleinere Chunks gebildet, diese sind aber mindestens 1800 Tokens lang (min_chunk_size). Die Chunks sind bevorzugt 2000 Tokens (max_chunk_size) lang.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winds1: 2000\n",
      "Winds2: 2000\n",
      "Boree1: 2000\n",
      "Auerbach1: 2000\n",
      "Halm1: 1929\n",
      "Friedell1: 2000\n",
      "Friedell2: 2000\n",
      "Friedell3: 2000\n",
      "Clefeld1: 2000\n",
      "Blei1: 2000\n",
      "Kreidemann1: 1804\n",
      "Vallentin1: 2000\n",
      "Hannsen1: 2000\n",
      "Hannsen2: 2000\n",
      "Olden1: 2000\n",
      "Olden2: 2000\n",
      "Bab1: 2000\n",
      "Bab2: 2000\n",
      "Martersteig1: 2000\n",
      "Martersteig2: 2000\n",
      "Martersteig3: 2000\n",
      "Kienscherf1: 2000\n",
      "Kienscherf2: 2000\n",
      "Kienscherf3: 2000\n",
      "Treitel1: 2000\n",
      "Treitel2: 2000\n",
      "Treitel3: 1931\n",
      "Bluemner1: 2000\n"
     ]
    }
   ],
   "source": [
    "max_amount_of_chunks = 3 # von jedem Autor werden höchstens 3 Chunks genommen\n",
    "min_chunk_size = 1800 # die Chunks müssen mindestens 1800 Tokens lang sein\n",
    "max_chunk_size = 2000 # und höchstens 2000 Tokens\n",
    "\n",
    "reference_pca_hac = {} # es wird wieder ein Dictionary in der Form Autor:[Tokens] erstellt\n",
    "\n",
    "for author in reference_corpus:\n",
    "    \n",
    "    chunk_start = 0\n",
    "    chunk_end = max_chunk_size # Die Chunks umfassen fürs erste die Tokens 0 bis 2000\n",
    "    \n",
    "    for n in range(max_amount_of_chunks): # Es wird 3 Mal über alle Texte iteriert\n",
    "    \n",
    "        while chunk_end <= max_amount_of_chunks * max_chunk_size:\n",
    "            tokens=reference_corpus[author][chunk_start:chunk_end] # Tokens 0 bis 2000 werden entnommen\n",
    "            if len(tokens) >= min_chunk_size: # es wird überprüft, ob es sich dabei um mehr als 1800 Tokens hält\n",
    "                author_short = author.split(\"_\")[1] # Vornamen werden gelöscht für übersichtlichere Darstellung bei der PCA\n",
    "                reference_pca_hac[f\"{author_short}{int(chunk_end/max_chunk_size)}\"]=tokens # Die Tokens werden dem Dict angefügt\n",
    "            chunk_start+=max_chunk_size # Beginn und Ende des Chunks werden erhöht für die nächste Iteration\n",
    "            chunk_end+=max_chunk_size\n",
    "            \n",
    "for author, text in reference_pca_hac.items():\n",
    "    print(f\"{author}: {len(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_pca_hac = [author for author in reference_pca_hac.keys()]\n",
    "documents_pca_hac = [\" \".join(text) for text in reference_pca_hac.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch von den drei Texten des Clowns werden jeweils die ersten 2000 Tokens genommen. Dieses Mal werden nicht mehr als diese drei Chunks des Clowns genommen, damit nicht einfach der Clown mit sich selbst clustert. Einer der Texte des Clowns ist ja leider kürzer als 2000 Tokens (sogar kürzer als 1800) und muss darum in nicht ganz vergleichbarer Länge verwendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1: 2000\n",
      "C2: 1641\n",
      "C3: 2000\n"
     ]
    }
   ],
   "source": [
    "max_chunk_size = 2000 # Chunks mit höchstens 2000 Tokens\n",
    "n = 1 # Nummer, mit der die 3 Chunks bezeichnet werden\n",
    "clown_pca_hac = {} # es wird wieder ein Dictionary in der Form Autor:[Tokens] erstellt\n",
    "\n",
    "for clown_text in corpus_clown: # Für jeden Text im Clown-Corpus:\n",
    "    \n",
    "    chunk_start = 0\n",
    "    chunk_end = max_chunk_size # Die Chunks umfassen die Tokens 0 bis höchstens 2000\n",
    "\n",
    "    tokens=corpus_clown[clown_text][0:max_chunk_size] # Tokens 0 bis maximal 2000  werden entnommen\n",
    "    clown_pca_hac[f\"C{n}\"]=tokens # Die Tokens werden dem Dict angefügt\n",
    "    n+=1 # Die Nummer für die Bezeichnung im Dicitionary wird erhöht              \n",
    "            \n",
    "for title, text in clown_pca_hac.items():\n",
    "    print(f\"{title}: {len(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "clown_titles_pca_hac = [title for title in clown_pca_hac.keys()]\n",
    "clown_pca_hac = [\" \".join(text) for text in clown_pca_hac.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Durchführen der PCA\n",
    "\n",
    "\n",
    "PCA wird grundsätzlich verwendet, um ein Vieldimensionales Datenset auf wenige Dimensionen zu reduzieren, um es zusammenzufassen und in Scatterplots darstellen zu können. Für Authorship Attribution sind solche Scatterplots sinnvoll, da man in ihnen sehen könnte, welche Texte welcher Autor\\*innen aufgrund ihrer Ähnlichkeit miteinander clustern oder, wenn sie z.B. von anderen Autor\\*innen sind, weiter auseinander stehen. PCA modelliert dafür Korrelationen zwischen Wortfrequenzen der most frequent words (meistens Funktionswörter), die starte Autorensignale sein können (Kestemont et al. 2015, S. 108). PCA kann einfach mit Scikit-Learn durchgeführt werden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing mit Anpassen der Vokabulargröße\n",
    "s_reference_pca, s_clown_pca = preprocess_corpus(documents_pca_hac, clown_pca_hac, vocab_75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduzieren der Dimensionen mit PCA\n",
    "pca = sklearn.decomposition.PCA(n_components=2)\n",
    "documents_proj = pca.fit_transform(s_reference_pca)\n",
    "var_exp = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die ursprüngliche DTM mit 28 Dokumenten umfasst 68 Dimensionen.\n",
      "\n",
      "Die dimensionsreduzierte DTM mit 28 Dokumenten umfasst 2 Dimensionen.\n"
     ]
    }
   ],
   "source": [
    "print(f'Die ursprüngliche DTM mit {s_reference_pca.shape[0]} Dokumenten umfasst {s_reference_pca.shape[1]} Dimensionen.\\n')\n",
    "print(f'Die dimensionsreduzierte DTM mit {documents_proj.shape[0]} Dokumenten umfasst {documents_proj.shape[1]} Dimensionen.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca(document_proj, var_exp, labels):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    x, y = documents_proj[:, 0], documents_proj[:, 1]\n",
    "    ax.scatter(x, y, facecolors='none')\n",
    "                    \n",
    "    for p1, p2, author in zip(x, y, labels):\n",
    "        color = 'red' if author in clown_names else 'black'\n",
    "        ax.text(p1, p2, \n",
    "                     author, \n",
    "                     ha='center',\n",
    "                     color=color, \n",
    "                     va='center', \n",
    "                     fontsize=12)\n",
    "\n",
    "    # add variance information to the axis labels:\n",
    "    ax.set_xlabel(f'PC1 ({var_exp[0] * 100:.2f}%)')\n",
    "    ax.set_ylabel(f'PC2 ({var_exp[1] * 100:.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents = np.vstack((s_reference_pca, s_clown_pca))\n",
    "all_documents = preprocessing.scale(np.vstack((s_reference_pca, s_clown_pca)))\n",
    "\n",
    "pca = sklearn.decomposition.PCA(n_components=2)\n",
    "documents_proj = pca.fit_transform(all_documents)\n",
    "var_exp = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_pca(documents_proj, var_exp, list(authors_pca_hac) + list(clown_titles_pca_hac))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "PCA erweist sich als ziemlich erfolglos für die untersuchten Texte. Während zwar viele Textchunks grundsätzlich miteinander clustern, können auch Textchunks derselben Autoren weit voneinander entfernt stehen. Auch die Texte des Clowns weisen keine besonders große Nähe zueinander auf. Das Scatterplot ist schwer zu interpretieren, für den Urheber der \"Clown\"-Texte gibt es keinen Aufschluss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 Durchführen der HAC\n",
    "\n",
    "Das Ziel des hierarchical agglomerative clustering ist es, Datenpunkte aufgrund großer Ähnlichkeiten zusammenzufassen. Während zu Beginn jeder Datenpunkt als einzelner Cluster betrachtet wird, werden diese Datenpunkte schrittweise zu Clustern zusammengefasst, bis am Ende alle Datenpunkte ein Cluster bilden. Dieser Prozess kann in einem Dendogramm (Baumdiagramm) abgebildet werden (Gadakari 2019). Die Zusammenfassung der Datenpunkte zu Clustern geschieht durch Berechnung eines Ähnlichkeitsmaßes (linkage), das auf verschiedene Arten berechnet werden kann („single“ = minimaler Abstand aller Elementpaare aus den beiden Clustern; „complete“ = maximaler Abstand aller Elementpaare aus beiden Clustern, „average“ = Durchschnitt aller Punkte). Im Folgenden werden zuerst die Distanzen zwischen allen Dokumenten („Clown“-Dokumente und Referenztexte wurden hierfür zusammengefasst) berechnet, danach wird mit der Einstellung der Berechnungsweise daraus das Linkage-Objekt erstellt, durch das dann Dendrogramm erzeugt wird. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing mit Anpassen der Vokabulargröße\n",
    "s_reference_hac, s_clown_hac = preprocess_corpus(documents_pca_hac, clown_pca_hac, vocab_100)\n",
    "all_documents = np.vstack((s_reference_hac, s_clown_hac))\n",
    "all_documents = preprocessing.scale(np.vstack((s_reference_hac, s_clown_hac)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der Distanzen\n",
    "dm = scidist.pdist(all_documents, 'cosine')\n",
    "\n",
    "# Erstellen des Dendrogramms\n",
    "linkage_object = hierarchy.linkage(dm, method='average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Darstellung des Dendrogramms\n",
    "\n",
    "def plot_tree_h(linkage_object, labels, figsize=(10, 5), ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "    with plt.rc_context({'lines.linewidth': 1.0}):\n",
    "        hierarchy.dendrogram(\n",
    "            linkage_object, \n",
    "            labels=labels, \n",
    "            ax=ax,\n",
    "            link_color_func=lambda c: 'black',\n",
    "            leaf_font_size=10, \n",
    "            leaf_rotation=0,\n",
    "            orientation='left')                 # horizontal\n",
    "            \n",
    "    # Remove ticks and spines\n",
    "    ax.xaxis.set_ticks_position('none')\n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "    for s in ax.spines.values():\n",
    "        s.set_visible(False)\n",
    "\n",
    "    ylabels = ax.get_ymajorticklabels()\n",
    "    for label in ylabels:                           # ylabels mit rot highlighten\n",
    "        if label.get_text() in clown_titles_pca_hac:\n",
    "            label.set_color('red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_tree_h(linkage_object, authors_pca_hac + clown_titles_pca_hac, figsize=(9, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "Auch hier clustern nicht einmal die Texte des \"Clowns\" mit sich selbst, Ähnlichkeiten der Textchunks der Autorenkandidaten sind durchaus zu beobachten (z.B. Friedell, Hannsen, Olden), gleichzeitig weisen die Texte der laut Delta wahrscheinlichsten Kandidaten Martersteig und Kienscherf auch mit sich selbst keine große Ähnlichkeit auf. Genau wie die PCA bleibt auch das Ergebnis der HAC schwer zu interpretieren. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Diskussion\n",
    "\n",
    "Ein eindeutiges Ergebnis, wer hinter dem Pseudonym „von einem Clown“ im Zeitraum von 1908 bis 1910 drei Texte für die Theaterzeitschrift *Die Schaubühne* verfasst hat, hat diese Untersuchung nicht ergeben. Während sich PCA und HAC als Methoden für dieses Korpus als völlig ungeeignet erwiesen und teilweise nicht einmal Ähnlichkeiten zwischen den Texten des unbekannten Autors selbst feststellen konnten (dass es sich beim Autor hinter allen „Clown“-Texten um ein und dieselbe Person handelt, ist immerhin relativ sicher, einerseits aufgrund der für eine\\*n menschliche\\*n Leser\\*in erkennbaren stilistischen Gemeinsamkeiten, andererseits aber auch, weil der Autor in der ersten Person Singular z.B. in „Theatertrust“ auf den früheren Text „Menschenhandel“ mit „wie ich bereits in einer früheren Schrift ausführlich nachgewiesen habe“ verweist), konnte mit Burrows Delta zumindest ein starker Verdacht ermittelt werden. Burrows Delta erwies sich dabei auch nur mit Tokens als zielführend, nicht aber mit Zeichen-N-Grammen, mit welchen keine eindeutigen und nicht interpretierbare Ergebnisse ermittelt wurden. \n",
    "\n",
    "Burrows Delta mit Tokens lässt Otto Johannes Kienscherf (7. April 1868 Magdeburg bis 11. Januar 1957 Hannover), Schauspieler, Regisseur und Dramaturg, als „Clown“ vermuten. Biographisch ist Kienscherf auf jeden Fall als „Clown“ denkbar. Neben dem Theater schrieb er Artikel für Tageszeitungen. Darüber hinaus beteiligte sich an der Ausbildung des Schauspielernachwuchses und setzte sich als Obmann der Genossenschaft Deutscher Bühnenangehöriger für die Verbesserung der sozialen Absicherung und eine Erhöhung der Tarifverträge für Schauspieler\\*innen ein (Gilbert 2015). Vom „Clown“ gibt es drei Texte in der *Schaubühne*: „Moderne Sklaven“ über die sklavenhaften, prekären Arbeitsbedingungen für Schauspieler\\*innen; „Menschenhandel“ direkt in der Me-Too-Debatte, das davon handelt, wie eine junge Schauspielerin von einem Theaterdirektor nach einem Besuch in dessen Zimmer engagiert wird; und Theatertrust über die schlechte Bezahlung von Schauspieler*innen. \n",
    "\n",
    "Problematisch bei den „Clown“-Texten, was eventuell zu den uneindeutigen Ergebnissen führt, sind außerdem die Unterschiede im Genre. „Theatertrust“ und „Moderne Sklaven“ sind relativ sachlich verfasst und der Autor beschreibt hier vor allem Fakten und seine Sichtweise, während „Menschenhandel“ in Form einer Geschichte, mit direkten Reden, verfasst ist und damit die Ergebnisse vielleicht schwerer interpretierbar macht. Darüber hinaus ist das Problem nicht außer Acht zu lassen, dass der richtige Autor der Texte vielleicht von Beginn an nicht berücksichtigt wurde, da er entweder nie für die *Schaubühne* unter Klarnamen geschrieben hat, manuell bereits zu früh aussortiert wurde, weil er aufgrund anderer Genres oder ganz anderer Themen als zu unplausibel erschienen ist, oder außer mit N-Grammen nicht weiter berücksichtigt wurde, weil zu wenig Tokens zu finden waren.\n",
    "\n",
    "Da jedoch sowohl der biographische Hintergrund als auch Delta mit Tokens so stark auf Otto Kienscherf hindeuten, soll zumindest für das Projekt im Rahmen dieses Seminars **Otto Kienscherf** als „Clown“ betrachtet werden. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quellen\n",
    "\n",
    "\n",
    "- Auerbach, Alfred: Vor- und Frühgeschichte des Gebiets von Ostthüringen zwischen Elster und Sahle, in: Geschichte der Stadt Weide in Einzeldarstellungen. 1 Band, 2, Heft, Thomas & Hubert, Weida 1927. \n",
    "- Austrian Academy of Sciences / Austrian Centre for Digital Humanities and Cultural Heritage: [Siegfried Jacobsohn: \"Die Schaubühne\"](https://www.oeaw.ac.at/de/acdh/projects/die-schaubuehne-siegfried-jacobsohn), 2022. \n",
    "- Blei, Franz: Erdachte Geschehnisse. Zehn Studien. Georg Müller, München und Leipzig, 1911.\n",
    "- Evert, Stefan et al.: Understanding and explaining Delta measures for authorship attribution, in: Digital Scholarship in the Humanities, 2017, Vol. 32, Supplement 2, S. 5-16. \n",
    "- Gadakari, Mahesh: [Hierarchical Agglomerative Clustering (HAC) with Single linkage method]( https://medium.com/@MaheshGadakari/hierarchical-agglomerative-clustering-hac-with-single-linkage-method-1159fa623d52), 2019. \n",
    "- Jacobsohn, Siegfried: Die Schaubühne (Bände 3.1 bis 8.2), 1906 bis 1913. \n",
    "- Kestemont, Mike et al: Collaborative authorship in the twelfth century: A stylometric study of Hildegard of Bingen and Guibert of Gembloux, in: Digital Scholarship in the Humanities, 2015, Vol. 30, No. 2, S. 199-224. \n",
    "- Kienscherf , Otto Johannes:  Schaubühne und Publikum, in: [Badisches Landestheater Karlsruhe. Almanach 1930](https://digital.blb-karlsruhe.de/blbihd/theaterzettel/periodical/titleinfo/1160900), hrsg. von Otto Kienscherf und Walther Landgrebe, Karlsruhe 1930, S. 34-38.\n",
    "- Gilbert, René: [Otto Johannes Kienscherf](https://stadtlexikon.karlsruhe.de/index.php/De:Lexikon:bio-0372), in: Stadtlexikon Karlsruhe, 2015. \n",
    "- Kienscherf , Otto Johannes: [Die Schaubühne der Zukunft](https://digi.ub.uni-heidelberg.de/diglit/suedwestdeutsche_rundschau1902/0315/image,info), in: Südwestdeutsche Rundschau. Halbmonatsschrift für deutsche Art und Kunst, Frankfurt a.M. 1902, Heft 8, S. 281-286.\n",
    "- Kienscherf , Otto Johannes: Scham wider Kunst, in: [Badisches Landestheater Karlsruhe. Almanach 1926/27](https://digital.blb-karlsruhe.de/blbihd/theaterzettel/periodical/titleinfo/1160900), hrsg. im Auftrag der Generaldirektion des Badischen Landestheaters von Werner Hugo Kaufmann, München 1926/27, S. 116-124. \n",
    "- Kienscherf , Otto Johannes: Vom künstlerischen Problem des Schauspielers, in: [Badisches Landestheater Karlsruhe. Almanach 1929]( https://digital.blb-karlsruhe.de/blbihd/theaterzettel/periodical/titleinfo/1160900), hrsg. vom Verlag Theaterkunst – Otto Glenk, München 1929, S. 45-58.\n",
    "- Martersteig, Max: Der Schauspieler. Ein künstlerisches Problem. Eine Studie. Eugen Diedrichs, Leipzig 1900.\n",
    "- Martersteig, Max: Die Bühne der Neuzeit, in: Das deutsche Theater im neunzehnten Jahrhundert. Eine kulturgeschichtliche Darstellung, Breitkopf & Härtel, Leipzig 1924. \n",
    "- Martersteig, Max: Die ethische Aufgabe der Schaubühne. Eine Schillerrede, Insel-Verlag, Leipzig 1912. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
